{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is dedicated to building and evaluating machine learning models for predicting the market value of football players. It leverages various regression algorithms to analyze player performance data and estimate their market value based on a number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries and connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# removes warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#suppress scientific notation by setting float_format\n",
    "pd.options.display.float_format = '{:.2f}'.format \n",
    "pd.set_option('display.max_rows', None) # display all rows\n",
    "pd.set_option('display.max_columns', None) # display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection details from environment variables\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "db_config = {\n",
    "    'dbname': os.getenv('DB_NAME'),\n",
    "    'user': os.getenv('DB_USER'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': int(os.getenv('DB_PORT'))  # Ensure the port is correctly converted to an integer\n",
    "}\n",
    "\n",
    "# Create a connection string for SQLAlchemy\n",
    "connection_string = f\"postgresql+psycopg2://{db_config['user']}:{db_config['password']}@{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "engine=create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_sql('SELECT * FROM prediction', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'gls', 'ast', 'pk', 'xg', 'npxg', 'xag', 'prgc', 'prgp',\n",
       "       'prgr', 'player_x', 'tkl_pcnt', 'lost', 'blocks', 'pass', 'int',\n",
       "       'tkl_plus_int', 'clr', 'err', 'sh', 'sot', 'sot_pcnt', 'sh_per_90',\n",
       "       'sot_per_90', 'g_per_sh', 'g_per_sot', 'dist', 'g_minus_xg', 'cmp',\n",
       "       'cmp_pcnt', 'totdist', 'prgdist', 'xa', 'kp', 'pass_into_final_third',\n",
       "       'ppa', 'crspa', 'touches', 'def_pen', 'att_pen', 'succ', 'succ_pcnt',\n",
       "       'tkld_pcnt', 'carries', 'carries_into_final_third', 'cpa', 'dis',\n",
       "       'player_id', 'player_y', 'main_position', 'value', 'height',\n",
       "       'current_club', 'league', 'days_until_expiry', 'age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['mp', 'starts', 'min', 'nineties','squad','birth_date_dt','matches','rec','mis','born_date','comp','live','a_minus_xag','date_of_birth', 'g_plus_a', 'g_minus_pk', 'pkatt', 'crdy', 'crdr', 'g_plus_a_minus_pk', 'xg_plus_xag', 'fk', 'npxg_plus_xag','tkld','tklw','birth_date', 'npxg_per_sh','np:g_minus_xg','contract_expiry','tkl', 'def_3rd', 'mid_3rd', 'att_3rd', 'att']\n",
    "df = df.drop(columns=columns_to_drop,axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Identifying important colunms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " columns_to_drop = ['mp', 'starts', 'min', 'nineties','squad','birth_date_dt','matches','rec','mis','born_date','comp','live','a_minus_xag','date_of_birth', 'g_plus_a', 'g_minus_pk', 'pkatt', 'crdy', 'crdr', 'g_plus_a_minus_pk', 'xg_plus_xag', 'fk', 'npxg_plus_xag','tkld','tklw','birth_date', 'npxg_per_sh','np:g_minus_xg','contract_expiry','tkl', 'def_3rd', 'mid_3rd', 'att_3rd', 'att']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Pre-processing\n",
    "\n",
    "In order to prepare the combined dataset for modeling, categorical features need to be encoded and numerical features need to be scaled.\n",
    "One hot encoding is performed for non-ordinal categorical variable as there was no order in the values of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ColumnTransformer is used to preprocess the data. This involves:\n",
    "\n",
    "One-hot encoding the categorical columns.\n",
    "\n",
    "Standard scaling the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'player_x', 'player_id', 'player_y', 'main_position',\n",
       "       'current_club', 'league'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_colums= df[df.select_dtypes(exclude=['int64', 'float64']).columns]\n",
    "str_colums.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MAE: 7685526.66, R²: 0.54\n",
      "Random Forest - MAE: 6849079.18, R²: 0.54\n",
      "Decision Tree - MAE: 8758067.73, R²: 0.24\n",
      "XGBoost - MAE: 6522798.63, R²: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Identify columns to be encoded\n",
    "categoric_columns = ['league', 'main_position', 'current_club']\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['value', 'unique_id', 'player_x', 'player_id', 'player_y'], axis=1)\n",
    "y = df['value']\n",
    "\n",
    "# Preprocess the data\n",
    "# OneHotEncode the object columns and StandardScale the numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), X.select_dtypes(include=['int64', 'float64']).columns),\n",
    "        ('cat', OneHotEncoder(), categoric_columns)\n",
    "    ])\n",
    "\n",
    "# Apply transformations\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'XGBoost': XGBRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results[model_name] = {'MAE': mae, 'R²': r2}\n",
    "\n",
    "# Print the results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name} - MAE: {metrics['MAE']:.2f}, R²: {metrics['R²']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=400, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=400, subsample=0.9; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=400, subsample=0.9; total time=   1.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.9; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.9; total time=   2.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   8.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   8.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   8.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=6, n_estimators=500, subsample=0.7; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=6, n_estimators=500, subsample=0.7; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=6, n_estimators=500, subsample=0.7; total time=   4.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=500, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.7; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.7; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=500, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.7; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=500, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=400, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=400, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=400, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   4.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=400, subsample=1.0; total time=   5.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   7.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=400, subsample=1.0; total time=   6.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=400, subsample=1.0; total time=   5.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.7; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.7; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.7; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=400, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=400, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=400, subsample=1.0; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   6.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   6.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, subsample=0.7; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=400, subsample=0.8; total time=   6.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=400, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=400, subsample=0.8; total time=   5.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   3.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   3.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.6; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.6; total time=   2.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   0.9s\n",
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.7}\n",
      "Final Model - MAE: 6443730.91, R²: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = XGBRegressor(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Final Model - MAE: {mae:.2f}, R²: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_model.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(final_model, 'xgboost_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocessor.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(preprocessor, 'preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "loaded_model = joblib.load('xgboost_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted market value for Harry Kane: 85441744.0\n"
     ]
    }
   ],
   "source": [
    "kane_row = df[df['player_y'] == 'Harry Kane']\n",
    "\n",
    "kane_features = kane_row.drop('value', axis=1)\n",
    "\n",
    "kane_processed = preprocessor.transform(kane_features)\n",
    "\n",
    "# Predict the market value\n",
    "kane_value = loaded_model.predict(kane_processed)\n",
    "\n",
    "print(f'Predicted market value for Harry Kane: {kane_value[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted market value for Mohamed Salah: 117132624.0\n"
     ]
    }
   ],
   "source": [
    "salah_row = df[df['player_x'] == 'Mohamed Salah']\n",
    "\n",
    "salah_features = salah_row.drop('value', axis=1)\n",
    "\n",
    "salah_processed = preprocessor.transform(salah_features)\n",
    "\n",
    "salah_value = final_model.predict(salah_processed)\n",
    "\n",
    "print(f'Predicted market value for Mohamed Salah: {salah_value[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted market value for Bruno Fernandes: 54369352.0\n"
     ]
    }
   ],
   "source": [
    "bruno_row = df[df['player_x'] == 'Bruno Fernandes']\n",
    "\n",
    "bruno_features = bruno_row.drop('value', axis=1)\n",
    "\n",
    "bruno_processed = preprocessor.transform(bruno_features)\n",
    "\n",
    "bruno_value = final_model.predict(bruno_processed)\n",
    "\n",
    "print(f'Predicted market value for Bruno Fernandes: {bruno_value[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'player_x', 'player_id', 'player_y', 'main_position',\n",
       "       'current_club', 'league'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_colums= df[df.select_dtypes(exclude=['int64', 'float64']).columns]\n",
    "str_colums.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "df=pd.read_sql('SELECT * FROM prediction', engine)  \n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['gls', 'ast', 'pk', 'xg', 'npxg', 'xag', 'prgc', 'prgp',\n",
    "       'prgr', 'tkl_pcnt', 'lost', 'blocks', 'pass', 'int',\n",
    "       'tkl_plus_int', 'clr', 'err', 'sh', 'sot', 'sot_pcnt', 'sh_per_90',\n",
    "       'sot_per_90', 'g_per_sh', 'g_per_sot', 'dist', 'g_minus_xg', 'cmp',\n",
    "       'cmp_pcnt', 'totdist', 'prgdist', 'xa', 'kp', 'pass_into_final_third',\n",
    "       'ppa', 'crspa', 'touches', 'def_pen', 'att_pen', 'succ', 'succ_pcnt',\n",
    "       'tkld_pcnt', 'carries', 'carries_into_final_third', 'cpa', 'dis',\n",
    "       'main_position', 'value', 'height',\n",
    "       'current_club', 'league', 'days_until_expiry', 'age']\n",
    "df = df[columns]\n",
    "\n",
    "\n",
    "# Fill missing values if any\n",
    "df = df.dropna()\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('value', axis=1)\n",
    "y = df['value']\n",
    "\n",
    "# Categorical columns\n",
    "categorical_cols = ['main_position',\n",
    "       'current_club', 'league']\n",
    "\n",
    "# Numeric columns\n",
    "numeric_cols = ['gls', 'ast', 'pk', 'xg', 'npxg', 'xag', 'prgc', 'prgp',\n",
    "       'prgr', 'tkl_pcnt', 'lost', 'blocks', 'pass', 'int',\n",
    "       'tkl_plus_int', 'clr', 'err', 'sh', 'sot', 'sot_pcnt', 'sh_per_90',\n",
    "       'sot_per_90', 'g_per_sh', 'g_per_sot', 'dist', 'g_minus_xg', 'cmp',\n",
    "       'cmp_pcnt', 'totdist', 'prgdist', 'xa', 'kp', 'pass_into_final_third',\n",
    "       'ppa', 'crspa', 'touches', 'def_pen', 'att_pen', 'succ', 'succ_pcnt',\n",
    "       'tkld_pcnt', 'carries', 'carries_into_final_third', 'cpa', 'dis', 'height',\n",
    "        'days_until_expiry', 'age']\n",
    "\n",
    "# Preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Preprocess the data\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Save the scaler\n",
    "scaler_filename = \"scaler.pkl\"\n",
    "joblib.dump(preprocessor, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 11213021.23, MAE: 7685480.89, R²: 0.54\n",
      "Decision Tree RMSE: 15806785.64, MAE: 9062350.60, R²: 0.09\n",
      "Random Forest RMSE: 11175390.60, MAE: 6812892.43, R²: 0.55\n",
      "Xgboost RMSE: 10749617.88, MAE: 6522798.63, R²: 0.58\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_preprocessed and y are already defined\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Xgboost': XGBRegressor()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{name} RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=500, subsample=0.8; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=300, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=400, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=400, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=400, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.9; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   6.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=7, n_estimators=500, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   4.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=7, n_estimators=200, subsample=0.6; total time=   5.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=6, n_estimators=500, subsample=0.7; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=6, n_estimators=500, subsample=0.7; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=6, n_estimators=500, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=500, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.7; total time=   7.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=500, subsample=0.9; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.7; total time=   7.0s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.7; total time=   7.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=500, subsample=0.9; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=400, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=500, subsample=0.6; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=400, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=4, n_estimators=400, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=4, n_estimators=300, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   2.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   4.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=400, subsample=1.0; total time=   3.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8; total time=   4.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.7; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=400, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=400, subsample=1.0; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   3.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   3.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.7; total time=   4.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.7; total time=   3.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=400, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=400, subsample=0.7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.7; total time=   3.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.6; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=400, subsample=1.0; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=400, subsample=1.0; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=400, subsample=1.0; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   1.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.8; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.8; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   3.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   9.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   9.1s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0; total time=   8.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   5.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8; total time=   5.8s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, subsample=0.7; total time=   7.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, subsample=0.7; total time=   7.4s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=7, n_estimators=400, subsample=0.7; total time=   6.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=400, subsample=0.8; total time=   6.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   2.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=400, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=7, n_estimators=400, subsample=0.8; total time=   6.6s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=3, n_estimators=400, subsample=0.7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   4.7s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   3.4s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   5.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9; total time=   5.2s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.7; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.6; total time=   2.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.6; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.6; total time=   3.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   2.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=500, subsample=1.0; total time=   1.5s\n",
      "Best parameters found:  {'subsample': 0.6, 'n_estimators': 500, 'max_depth': 4, 'learning_rate': 0.05, 'colsample_bytree': 0.7}\n",
      "Final Model - RMSE: 10234772.57, MAE: 6265473.24, R²: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "final_model = XGBRegressor(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Final Model - RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgboost.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(final_model, 'best_xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "import joblib\n",
    "loaded_model = joblib.load('best_xgboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
